{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model with the help of data present in image folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folders inside image folder and save those folders with the name of the person and then put the data in that folder so that your model can learn from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "image_dir = os.path.join(BASE_DIR, \"images\")\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "current_id = 0\n",
    "label_ids = {}\n",
    "\n",
    "y_labels = []\n",
    "x_train = []\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path = os.path.join(root,file)\n",
    "            label = os.path.basename(root).replace(\" \",\"-\").lower()\n",
    "            #print(label,path)\n",
    "            \n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1 \n",
    "            \n",
    "            id_ = label_ids[label]\n",
    "            #print(label_ids)\n",
    "            #y_labels.append(label) # some number\n",
    "            #x_train.append(path) # verify this image, turn into a NUMPY array, and convert it into GRAY image\n",
    "            \n",
    "            pil_image = Image.open(path).convert(\"L\") # grayscale\n",
    "            size = (550,550)\n",
    "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            image_array = np.array(final_image,\"uint8\")\n",
    "            #print(image_array)\n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.1, minNeighbors=4)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h, x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "                \n",
    "#print(y_labels)\n",
    "#print(x_train)\n",
    "\n",
    "with open(\"labels.pickle\", \"wb\") as f:\n",
    "    pickle.dump(label_ids, f)\n",
    "    \n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(\"trainner.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\")\n",
    "\n",
    "labels = {\"person_name\": 1}\n",
    "with open(\"labels.pickle\", \"rb\") as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels = {v:k for k,v in og_labels.items()}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        #print(x,y,w,h)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # recognize? deep learning model predict keras tensorflow pytorch scikit learn \n",
    "        id_,conf = recognizer.predict(roi_gray)\n",
    "        if conf>=45 and conf<=85:\n",
    "            #print(id_)\n",
    "            #print(labels[id_])\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            cv2.putText(frame, name, (x,y), font, 1, (255,255,255), 2,cv2.LINE_AA)\n",
    "        img_item = \"my-image.png\"\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "\n",
    "    cv2.imshow('f', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
